{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b833f7c",
   "metadata": {},
   "source": [
    "# Exercise : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52ba324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
      "0                0.38             0.53               2                   157   \n",
      "1                0.80             0.86               5                   262   \n",
      "2                0.11             0.88               7                   272   \n",
      "3                0.72             0.87               5                   223   \n",
      "4                0.37             0.52               2                   159   \n",
      "\n",
      "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
      "0                   3              0     1                      0  sales   \n",
      "1                   6              0     1                      0  sales   \n",
      "2                   4              0     1                      0  sales   \n",
      "3                   5              0     1                      0  sales   \n",
      "4                   3              0     1                      0  sales   \n",
      "\n",
      "   salary  \n",
      "0     low  \n",
      "1  medium  \n",
      "2  medium  \n",
      "3     low  \n",
      "4     low  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   sales                  14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "       satisfaction_level  last_evaluation  number_project  \\\n",
      "count        14999.000000     14999.000000    14999.000000   \n",
      "mean             0.612834         0.716102        3.803054   \n",
      "std              0.248631         0.171169        1.232592   \n",
      "min              0.090000         0.360000        2.000000   \n",
      "25%              0.440000         0.560000        3.000000   \n",
      "50%              0.640000         0.720000        4.000000   \n",
      "75%              0.820000         0.870000        5.000000   \n",
      "max              1.000000         1.000000        7.000000   \n",
      "\n",
      "       average_montly_hours  time_spend_company  Work_accident          left  \\\n",
      "count          14999.000000        14999.000000   14999.000000  14999.000000   \n",
      "mean             201.050337            3.498233       0.144610      0.238083   \n",
      "std               49.943099            1.460136       0.351719      0.425924   \n",
      "min               96.000000            2.000000       0.000000      0.000000   \n",
      "25%              156.000000            3.000000       0.000000      0.000000   \n",
      "50%              200.000000            3.000000       0.000000      0.000000   \n",
      "75%              245.000000            4.000000       0.000000      0.000000   \n",
      "max              310.000000           10.000000       1.000000      1.000000   \n",
      "\n",
      "       promotion_last_5years  \n",
      "count           14999.000000  \n",
      "mean                0.021268  \n",
      "std                 0.144281  \n",
      "min                 0.000000  \n",
      "25%                 0.000000  \n",
      "50%                 0.000000  \n",
      "75%                 0.000000  \n",
      "max                 1.000000  \n",
      "Confusion Matrix:\n",
      "[[2294    0]\n",
      " [   0  706]]\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('HR_comma_sep.csv')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Check for numeric features that may need rescaling\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Standardize the numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Convert categorical features into dummy/indicator variables\n",
    "categorical_features = data.select_dtypes(include=['object'])\n",
    "dummies = pd.get_dummies(categorical_features, drop_first=True)\n",
    "\n",
    "# Combine scaled numeric features with dummies\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=numeric_features.columns)\n",
    "final_data = pd.concat([scaled_df, dummies], axis=1)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = final_data\n",
    "y = data['left']  # Assuming 'left' is the target variable indicating if the employee left\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', max_iter=200)  # Using 'liblinear' for small datasets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion matrix, precision, and recall\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674de89e",
   "metadata": {},
   "source": [
    "# Exercise : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d19087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
      "0                0.38             0.53               2                   157   \n",
      "1                0.80             0.86               5                   262   \n",
      "2                0.11             0.88               7                   272   \n",
      "3                0.72             0.87               5                   223   \n",
      "4                0.37             0.52               2                   159   \n",
      "\n",
      "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
      "0                   3              0     1                      0  sales   \n",
      "1                   6              0     1                      0  sales   \n",
      "2                   4              0     1                      0  sales   \n",
      "3                   5              0     1                      0  sales   \n",
      "4                   3              0     1                      0  sales   \n",
      "\n",
      "   salary  \n",
      "0     low  \n",
      "1  medium  \n",
      "2  medium  \n",
      "3     low  \n",
      "4     low  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   sales                  14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "       satisfaction_level  last_evaluation  number_project  \\\n",
      "count        14999.000000     14999.000000    14999.000000   \n",
      "mean             0.612834         0.716102        3.803054   \n",
      "std              0.248631         0.171169        1.232592   \n",
      "min              0.090000         0.360000        2.000000   \n",
      "25%              0.440000         0.560000        3.000000   \n",
      "50%              0.640000         0.720000        4.000000   \n",
      "75%              0.820000         0.870000        5.000000   \n",
      "max              1.000000         1.000000        7.000000   \n",
      "\n",
      "       average_montly_hours  time_spend_company  Work_accident          left  \\\n",
      "count          14999.000000        14999.000000   14999.000000  14999.000000   \n",
      "mean             201.050337            3.498233       0.144610      0.238083   \n",
      "std               49.943099            1.460136       0.351719      0.425924   \n",
      "min               96.000000            2.000000       0.000000      0.000000   \n",
      "25%              156.000000            3.000000       0.000000      0.000000   \n",
      "50%              200.000000            3.000000       0.000000      0.000000   \n",
      "75%              245.000000            4.000000       0.000000      0.000000   \n",
      "max              310.000000           10.000000       1.000000      1.000000   \n",
      "\n",
      "       promotion_last_5years  \n",
      "count           14999.000000  \n",
      "mean                0.021268  \n",
      "std                 0.144281  \n",
      "min                 0.000000  \n",
      "25%                 0.000000  \n",
      "50%                 0.000000  \n",
      "75%                 0.000000  \n",
      "max                 1.000000  \n",
      "Train features shape: (11999, 19)\n",
      "Test features shape: (3000, 19)\n",
      "Train target shape: (11999,)\n",
      "Test target shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('HR_comma_sep.csv')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Check for numeric features that may need rescaling\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Standardize the numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Convert categorical features into dummy/indicator variables\n",
    "categorical_features = data.select_dtypes(include=['object'])\n",
    "dummies = pd.get_dummies(categorical_features, drop_first=True)\n",
    "\n",
    "# Combine scaled numeric features with dummies\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=numeric_features.columns)\n",
    "final_data = pd.concat([scaled_df, dummies], axis=1)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = final_data\n",
    "y = data['left']  # Assuming 'left' is the target variable indicating if the employee left\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display shapes of the resulting datasets\n",
    "print(f'Train features shape: {X_train.shape}')\n",
    "print(f'Test features shape: {X_test.shape}')\n",
    "print(f'Train target shape: {y_train.shape}')\n",
    "print(f'Test target shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd878701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
